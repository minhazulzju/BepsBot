<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BepsBot System Presentation</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <header>
        <h1>BepsBot: AI-Powered Peer Support Writing Assistant</h1>
        <nav>
            <a href="#problem">Problem</a>
            <a href="#overview">Overview</a>
            <a href="#architecture">System Architecture</a>
                <a href="#how">How BepsBot Works</a>
            <a href="#features">Features & Tech Stack</a>
            <a href="#results">Results & Impact</a>
            <a href="#contact">Contact</a>
        </nav>
    </header>
    
    <!-- Try BepsBot Section -->
    <div class="try-bepsbot-banner">
        <div class="try-bepsbot-content">
            <img src="bepsbot.png" alt="BepsBot Logo" class="bepsbot-logo">
            <div class="try-bepsbot-text">
                <h2>Ready to try BepsBot?</h2>
                <p>Experience AI-powered peer support writing assistance now!</p>
                <a href="http://104.214.178.64:5000/" target="_blank" class="try-bepsbot-btn">Launch BepsBot</a>
            </div>
        </div>
    </div>
    
    <main>
        <section id="problem">
            <h2>Problem & Motivation</h2>
            <p>
                <b>Online mental health communities (OMHCs)</b> are vital spaces for peer support, but users often
                struggle to write comments that are both empathetic and informative. Many comments lack either emotional
                support (ES) or informational support (IS), and users may feel uncertain about the quality or
                helpfulness of their responses. Traditional writing assistance tools are not tailored for the sensitive,
                high-stakes context of mental health support, and can frustrate users or lead to insincere, repetitive,
                or even risky content. There is a clear need for intelligent, context-aware tools that can guide users
                to compose high-quality, safe, and supportive comments in real time.
            </p>
        </section>
            <section id="how">
                <h2>How BepsBot Works</h2>
                <h3>Data Collection and Annotation</h3>
                <p>BepsBot’s data pipeline initiates with the large-scale extraction of mental health discussions from Reddit, encompassing six years of posts and comments. Leveraging the Pushshift API, the system systematically collects and aggregates this data, which is then subjected to comprehensive processing, cleaning, normalization, and formatting. To ensure both data quality and computational efficiency, only comments that meet stringent length and relevance criteria are retained, forming a robust raw data lake.</p>
                <p>A domain expert annotation interface is employed to label a representative sample of comments for Informational Support (IS) and Emotional Support (ES) on a three-point ordinal scale (low, medium, high). IS is operationalized as the presence of advice, referrals, or knowledge, while ES is defined by evidence of understanding, encouragement, affirmation, sympathy, or caring. Multiple annotators independently label the data, with rigorous quality control and validation procedures ensuring high inter-rater reliability (Cohen’s κ &gt; 0.85). Discrepancies are adjudicated by a third expert, resulting in a gold-standard dataset for supervised learning.</p>
                <h3>Model Training and Active Learning</h3>
                <p>The expertly annotated dataset serves as the foundation for training and fine-tuning advanced transformer-based models, such as RoBERTa, for regression-based IS/ES scoring. The modeling pipeline incorporates custom regression heads and loss function optimization, with model performance evaluated using standard metrics (e.g., F1 score, R²). BepsBot employs an active learning loop: new user interactions are pseudo-labeled, filtered for quality, and iteratively incorporated into retraining cycles. This enables continuous model refinement, domain adaptation, and seamless deployment of updated models.</p>
                <h3>Assessment (AS) Mode</h3>
                <p>In assessment mode, BepsBot delivers real-time, actionable feedback on user-generated comments. Upon receiving a draft, the system predicts IS and ES levels using the trained RoBERTa-based regression models. Feedback is generated by identifying a single, actionable improvement point from four key feature domains:</p>
                <ul>
                    <li><b>Length-based features:</b> Word and sentence counts, as higher counts are often indicative of greater IS and ES.</li>
                    <li><b>Personal pronouns:</b> Usage of pronouns such as “I,” “we,” “you,” “she/he,” and “they,” which can signal supportiveness and engagement.</li>
                    <li><b>Social words:</b> Terms related to friends and family, which are particularly salient for IS.</li>
                    <li><b>Positive emotion words:</b> Lexical indicators of positivity, which are critical for ES.</li>
                </ul>
                <p>To prevent cognitive overload, BepsBot suggests only one improvement at a time, prioritizing length-based feedback on the first occurrence and randomly selecting among the remaining features for subsequent suggestions. Each feedback message is accompanied by a curated set of example words to inspire user revisions, with multiple feedback scripts employed to sustain user engagement and variety.</p>
                <h3>Recommendation (RE) Mode</h3>
                <p>BepsBot’s recommendation mode is powered by a retrieval-augmented generation (RAG) pipeline, which synergistically integrates semantic search with large language models (LLMs) to provide context-aware, high-quality suggestions. The workflow is as follows:</p>
                <ol>
                    <li><b>Contextual Retrieval:</b> The user’s draft is embedded using Sentence Transformers and used to query a ChromaDB vector database, retrieving the top-K semantically similar, high-quality responses from a curated pool.</li>
                    <li><b>LLM Integration:</b> The retrieved context is dynamically injected into a prompt for the LLM (e.g., DeepSeek), which then generates several alternative, supportive comment suggestions—each tailored to emphasize positive emotion, personal pronouns, or social/family language.</li>
                    <li><b>Safety and Quality Filtering:</b> All user inputs and LLM-generated outputs are rigorously screened by an LLM-based safety filter, ensuring that only ethical, safe, and responsible content is delivered.</li>
                    <li><b>User Experience:</b> Recommendations are presented in an intuitive, user-friendly interface, with key linguistic features highlighted and navigation controls provided for seamless browsing.</li>
                </ol>
                <p>This hybrid approach ensures that BepsBot consistently delivers safe, relevant, and diverse suggestions, grounded in both expert-annotated data and real-time generative AI, while continuously improving through active learning and user feedback.</p>
            </section>
        <section id="overview">
            <h2>Solution: BepsBot Overview</h2>
            <p>BepsBot is a modular AI system leveraging large language models (LLMs), vector databases, and advanced
                NLP pipelines to assist users in composing high-quality, supportive comments in online mental health
                communities. The system integrates Retrieval-Augmented Generation (RAG), prompt engineering, and
                fine-tuned models for real-time feedback and recommendations.</p>
        </section>
        <section id="architecture">
            <h2>System Architecture</h2>
            <div class="diagram">
                <img src="architecture1.png" alt="RAG Pipeline Diagram" style="max-width:100%;height:auto;">
            </div>
            <div class="diagram">
                <img src="architecture2.png" alt="Data Pipeline Diagram" style="max-width:100%;height:auto;">
            </div>
            <div class="diagram">
                <img src="architecture3.png" alt="System Data Flow Diagram" style="max-width:100%;height:auto;">
            </div>
            <h3>Technical Details</h3>
            <p><b>Why use RAG?</b> RAG (Retrieval-Augmented Generation) allows the system to dynamically inject
                relevant, high-quality peer support examples into the LLM’s context at inference time. This provides
                up-to-date, context-aware guidance and avoids the limitations of static fine-tuning, which can struggle
                to generalize or adapt to new topics and user needs. RAG also reduces hallucination and improves
                factuality by grounding responses in real data.</p>
            <ul>
                <li><b>LLM Integration & Orchestration:</b> Modular backend supports both local and API-based LLMs
                    (OpenAI, HuggingFace Transformers). LLMs are used for content generation, scoring, and safety
                    filtering. The system is designed for easy swapping and fine-tuning of models for specific tasks.
                </li>
                <li><b>Retrieval-Augmented Generation (RAG) Pipeline:</b> User queries are embedded using Sentence
                    Transformers (MiniLM, RoBERTa). Embeddings are stored and searched in ChromaDB, a high-performance
                    vector database. Top-K relevant responses are retrieved and injected as context for LLM-based
                    generation, enabling context-aware, high-recall outputs.</li>
                <li><b>Why RAG over just fine-tuning?</b> RAG enables the system to dynamically inject relevant,
                    high-quality peer support examples into the LLM's context at inference time. This provides
                    up-to-date, context-aware guidance and avoids the limitations of static fine-tuning, which can
                    struggle to generalize or adapt to new topics and user needs. RAG also reduces hallucination and
                    improves factuality by grounding responses in real data.</li>
                <li><b>Why ChromaDB?</b> ChromaDB was selected for its sub-millisecond retrieval speed, enabling
                    real-time, low-latency semantic search crucial for user-facing applications. Through careful index
                    tuning and hardware optimization, we reduced end-to-end retrieval latency by 65%, ensuring seamless
                    user experience even at scale.</li>
                <li><b>LLM Latency Optimization:</b> We optimized for low latency by combining sub-millisecond retrieval
                    from ChromaDB with prompt engineering to keep LLM inputs concise and relevant. Where possible, we
                    batch requests and use efficient model endpoints. These strategies, along with hardware and software
                    optimizations, significantly reduce user-perceived wait times.</li>
                <li><b>Prompt Engineering:</b> Dynamic prompt templates are constructed based on user intent (assessment
                    vs. recommendation). Prompts include retrieved examples, safety instructions, and user context to
                    guide LLM output and minimize hallucination.</li>
                <li><b>Model Training & Fine-Tuning:</b> IS/ES classifiers are trained on annotated Reddit data using
                    Random Forest, XGBoost, and fine-tuned RoBERTa. LLMs are further fine-tuned on domain-specific
                    support conversations, with custom heads for regression/classification. Evaluation includes
                    cross-validation, F1/accuracy metrics, and human-in-the-loop validation.</li>
                <li><b>Active Learning Loop:</b> User interactions are logged and periodically used to retrain models,
                    improving performance and domain adaptation. The pipeline supports continuous deployment and model
                    versioning.</li>
                <li><b>Engineering Best Practices:</b> RESTful API endpoints (FastAPI), containerized deployment
                    (Docker), robust monitoring/logging, and modular codebase for scalability and maintainability.</li>
                <li><b>Safety & Hallucination Filtering:</b> Safety is enforced through a multi-layered approach: all
                    user inputs and LLM outputs are screened by both rule-based and LLM-based content filters. These
                    filters block or flag harmful, unsafe, or privacy-violating content before it reaches the user. The
                    system is regularly updated with new safety rules and leverages human-in-the-loop review for
                    continuous improvement.</li>
            </ul>
            <p><b>Key components:</b> Flask frontend, FastAPI backend, ChromaDB vector search, LLM orchestration, safety
                filtering, and active learning loop.</p>
        </section>
        <section id="features">
            <h2>Features & Technology Stack</h2>
            <ul>
                <li><b>Retrieval-Augmented Generation (RAG):</b> Combines semantic search (ChromaDB) with LLMs for
                    context-aware response generation.</li>
                <li><b>Prompt Engineering:</b> Dynamic prompt templates for LLMs, including context injection and safety
                    instructions.</li>
                <li><b>Fine-Tuning:</b> Domain-specific adaptation of open-source models (RoBERTa, MiniLM) for IS/ES
                    scoring and recommendation.</li>
                <li><b>Safety & Hallucination Filtering:</b> LLM-based and rule-based content filters for trustworthy
                    outputs.</li>
                <li><b>Active Learning:</b> User feedback loop for continuous model improvement.</li>
            </ul>
            <h3>Technology Stack</h3>
            <ul>
                <li>Python, Flask, FastAPI</li>
                <li>PyTorch, HuggingFace Transformers</li>
                <li>ChromaDB (vector database)</li>
                <li>Docker (containerization)</li>
                <li>JavaScript (frontend-backend communication)</li>
            </ul>
        </section>
        <section id="results">
            <h2>Results & Impact</h2>
            <ul>
                <li>IS/ES scoring accuracy: 65–75% (validated on expert-labeled data)</li>
                <li>Scalable, real-time RAG pipeline for recommendations and feedback</li>
                <li>Safe, context-aware outputs with integrated hallucination detection</li>
            </ul>
        </section>
        <section id="contact">
            <h2>Contact / About</h2>
            <p>Project by MINHAZUL ISLAM. For more information, please contact: <a
                    href="mailto:minhaz1396@zju.edu.cn">minhaz1396@zju.edu.cn</a></p>
        </section>
        <section id="faq">
            <!-- FAQ section removed; content integrated into Technical Details -->
    </main>
    <footer>
        <p>&copy; 2025 BepsBot Project</p>
    </footer>
    <script src="main.js"></script>
</body>


</html>
